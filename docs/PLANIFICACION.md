# ğŸ“‹ PlanificaciÃ³n del Proyecto

## TipoCambio.pe - DiseÃ±o y Desarrollo

---

## 1. Objetivos del Proyecto

### Objetivo General
Desarrollar un sistema automatizado de extracciÃ³n y comparaciÃ³n de tipos de cambio de mÃºltiples fuentes en PerÃº, generando un dataset histÃ³rico estructurado.

### Objetivos EspecÃ­ficos
1. Extraer datos del tipo de cambio oficial del BCRP mediante su API REST
2. Realizar web scraping de casas de cambio digitales (Kambista, Rextie)
3. Integrar las fuentes en un dataset unificado con estructura consistente
4. Automatizar la extracciÃ³n cada 1 hora con detecciÃ³n de cambios
5. Documentar el cÃ³digo siguiendo buenas prÃ¡cticas de Python

---

## 2. Cronograma de Desarrollo

| Fase | Tarea | Responsable | Fecha | Estado |
|------|-------|-------------|-------|--------|
| 1 | Crear repositorio GitHub | Javier | 13/12/2024 | âœ… |
| 1 | Definir estructura del proyecto | Equipo | 13/12/2024 | âœ… |
| 2 | Desarrollar scraper BCRP | Javier | 14/12/2024 | â³ |
| 2 | Desarrollar scraper Kambista | Fiorella | 14/12/2024 | â³ |
| 2 | Desarrollar scraper Rextie | SebastiÃ¡n | 14/12/2024 | â³ |
| 3 | Integrar fuentes | Javier | 15/12/2024 | â³ |
| 3 | Testing y correcciones | Equipo | 15/12/2024 | â³ |
| 4 | DocumentaciÃ³n final | Fiorella | 15/12/2024 | â³ |
| 4 | Preparar presentaciÃ³n | Equipo | 16/12/2024 | â³ |
| 5 | **ExposiciÃ³n final** | Equipo | 16/12/2024 | â³ |

---

## 3. DiseÃ±o de la ExtracciÃ³n

### 3.1 Fuente 1: API BCRP

**Endpoint:** 
```
https://estadisticas.bcrp.gob.pe/estadisticas/series/api/[series]/[formato]/[periodo_inicial]/[periodo_final]
```

**Series utilizadas:**
- `PD04638PD` - Tipo de cambio compra
- `PD04639PD` - Tipo de cambio venta

**Proceso:**
1. Construir URL con fecha actual
2. Hacer peticiÃ³n GET con requests
3. Parsear respuesta JSON
4. Extraer valores de compra y venta
5. Retornar diccionario con datos

**Manejo de errores:**
- Timeout de conexiÃ³n
- Error de parseo JSON
- Datos no disponibles

### 3.2 Fuente 2: Web Scraping Kambista

**URL:** `https://kambista.com`

**Proceso:**
1. Hacer peticiÃ³n GET con headers de navegador
2. Parsear HTML con BeautifulSoup
3. Localizar elementos con tasas de cambio
4. Extraer valores numÃ©ricos
5. Retornar diccionario con datos

**Selectores CSS/XPath:**
- Tasa compra: (por definir tras inspecciÃ³n)
- Tasa venta: (por definir tras inspecciÃ³n)

**Consideraciones Ã©ticas:**
- Respetar robots.txt
- Frecuencia baja (1 peticiÃ³n/hora)
- User-agent realista

### 3.3 Fuente 3: Web Scraping Rextie

**URL:** `https://rextie.com`

**Proceso:** Similar a Kambista

**Selectores CSS/XPath:**
- Tasa compra: (por definir tras inspecciÃ³n)
- Tasa venta: (por definir tras inspecciÃ³n)

---

## 4. DiseÃ±o de IntegraciÃ³n de Datos

### 4.1 Flujo de Datos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API BCRP   â”‚     â”‚  Kambista   â”‚     â”‚   Rextie    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚                   â”‚
       â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INTEGRADOR                         â”‚
â”‚  - Combina datos de 3 fuentes                        â”‚
â”‚  - Calcula spreads                                   â”‚
â”‚  - Determina mejor opciÃ³n                            â”‚
â”‚  - Detecta cambios vs registro anterior              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              tipo_cambio_historico.csv               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 LÃ³gica de DetecciÃ³n de Cambios

```python
def hubo_cambio(datos_nuevos, datos_anteriores):
    """
    Compara datos nuevos con el Ãºltimo registro.
    Retorna True si algÃºn valor cambiÃ³.
    """
    campos_a_comparar = [
        'tc_bcrp_compra', 'tc_bcrp_venta',
        'tc_kambista_compra', 'tc_kambista_venta',
        'tc_rextie_compra', 'tc_rextie_venta'
    ]
    
    for campo in campos_a_comparar:
        if datos_nuevos[campo] != datos_anteriores[campo]:
            return True
    return False
```

### 4.3 CÃ¡lculo de MÃ©tricas

```python
# Spread = Venta - Compra
spread_bcrp = tc_bcrp_venta - tc_bcrp_compra
spread_kambista = tc_kambista_venta - tc_kambista_compra
spread_rextie = tc_rextie_venta - tc_rextie_compra

# Mejor opciÃ³n para COMPRAR dÃ³lares (quiero el precio mÃ¡s bajo de venta)
mejor_compra = min([
    ('BCRP', tc_bcrp_venta),
    ('Kambista', tc_kambista_venta),
    ('Rextie', tc_rextie_venta)
], key=lambda x: x[1])[0]

# Mejor opciÃ³n para VENDER dÃ³lares (quiero el precio mÃ¡s alto de compra)
mejor_venta = max([
    ('BCRP', tc_bcrp_compra),
    ('Kambista', tc_kambista_compra),
    ('Rextie', tc_rextie_compra)
], key=lambda x: x[1])[0]
```

---

## 5. Estructura del CSV Final

### Ejemplo de registro:

```csv
timestamp,tc_bcrp_compra,tc_bcrp_venta,tc_kambista_compra,tc_kambista_venta,tc_rextie_compra,tc_rextie_venta,spread_bcrp,spread_kambista,spread_rextie,mejor_compra,mejor_venta
2024-12-13 10:00:00,3.720,3.760,3.735,3.755,3.730,3.750,0.040,0.020,0.020,Rextie,Kambista
```

---

## 6. AutomatizaciÃ³n

### Usando schedule (Python)

```python
import schedule
import time

def job():
    print("Ejecutando extracciÃ³n...")
    ejecutar_extraccion()

# Programar cada 1 hora
schedule.every(1).hours.do(job)

while True:
    schedule.run_pending()
    time.sleep(60)
```

---

## 7. DistribuciÃ³n de Trabajo

### Javier Uraco (@JavierAnthonyUS)
- [x] Crear repositorio GitHub
- [ ] Desarrollar `scraper_bcrp.py`
- [ ] Desarrollar `integrador.py`
- [ ] Configurar automatizaciÃ³n

### Fiorella Fuentes (@fiorellafuentesb20-cell)
- [ ] Desarrollar `scraper_kambista.py`
- [ ] Documentar fuentes de datos
- [ ] Crear diccionario de datos
- [ ] Revisar README

### SebastiÃ¡n FernÃ¡ndez (@TucoSquare)
- [ ] Desarrollar `scraper_rextie.py`
- [ ] Desarrollar `utils.py`
- [ ] Testing de scrapers
- [ ] Preparar datos de ejemplo

---

## 8. Riesgos Identificados

| Riesgo | Probabilidad | Impacto | MitigaciÃ³n |
|--------|--------------|---------|------------|
| Bloqueo por scraping | Media | Alto | Frecuencia baja, headers realistas |
| Cambio en estructura HTML | Alta | Medio | CÃ³digo modular, fÃ¡cil actualizaciÃ³n |
| API BCRP caÃ­da | Baja | Medio | Try-catch, continuar con otras fuentes |
| Conflictos en Git | Media | Bajo | ComunicaciÃ³n, ramas separadas |

---

## 9. Criterios de Ã‰xito

- âœ… ExtracciÃ³n funcional de 3 fuentes
- âœ… Dataset CSV con al menos 24 registros (1 dÃ­a de datos)
- âœ… CÃ³digo documentado con docstrings
- âœ… Commits de todos los integrantes en GitHub
- âœ… ExposiciÃ³n clara de 20-25 minutos

---

*Documento creado: 13/12/2024*
*Ãšltima actualizaciÃ³n: 13/12/2024*
