# üîß DIFICULTADES Y SOLUCIONES
## Proyecto TipoCambio.pe - LP2 UNALM 2025

Este documento detalla los principales desaf√≠os t√©cnicos encontrados durante el desarrollo del proyecto y las soluciones implementadas.

---

## üìã Resumen de Dificultades

| # | Dificultad | Problema espec√≠fico | Soluci√≥n aplicada |
|---|------------|---------------------|-------------------|
| 1 | P√°ginas din√°micas | BeautifulSoup retornaba HTML vac√≠o | Selenium con Chrome headless |
| 2 | Identificaci√≥n de valores | Muchos n√∫meros en la p√°gina | Regex + filtro por rango 3.30-3.50 |
| 3 | Tiempos de espera | Selenium tardaba mucho | Optimizaci√≥n de waits |
| 4 | API BCRP | Formato de fechas espec√≠fico | Funci√≥n para generar rango de fechas |
| 5 | Compatibilidad NiceGUI | Cambios en versi√≥n 3.4.1 | Adaptar componentes UI |
| 6 | Coordinaci√≥n de equipo | Diferentes horarios y tareas | GitHub + commits descriptivos |

---

## üîç Detalle de cada dificultad

---

### 1Ô∏è‚É£ P√ÅGINAS DIN√ÅMICAS

#### Problema
Kambista y Rextie son p√°ginas web que cargan sus datos de tipo de cambio usando **JavaScript**. Cuando intentamos usar `requests` + `BeautifulSoup`, obten√≠amos el HTML inicial sin los precios.

```python
# ‚ùå ESTO NO FUNCIONABA
import requests
from bs4 import BeautifulSoup

response = requests.get("https://kambista.com")
soup = BeautifulSoup(response.text, 'html.parser')
# El HTML no conten√≠a los precios porque JavaScript no se hab√≠a ejecutado
```

#### ¬øPor qu√© ocurre?
- `requests` solo descarga el HTML inicial
- Los precios se cargan despu√©s mediante llamadas JavaScript/AJAX
- BeautifulSoup no ejecuta JavaScript

#### Soluci√≥n
Implementamos **Selenium** con Chrome en modo headless para renderizar la p√°gina completa:

```python
# ‚úÖ SOLUCI√ìN CON SELENIUM
from selenium import webdriver
from selenium.webdriver.chrome.options import Options

options = Options()
options.add_argument('--headless')  # Sin ventana visible
options.add_argument('--disable-gpu')
options.add_argument('--no-sandbox')

driver = webdriver.Chrome(options=options)
driver.get("https://kambista.com")
time.sleep(5)  # Esperar que JavaScript cargue

# Ahora s√≠ tenemos el HTML con los precios
page_source = driver.page_source
```

#### Lecci√≥n aprendida
> No todas las p√°ginas web pueden ser scrapeadas con BeautifulSoup. Las p√°ginas modernas con frameworks como React, Vue o Angular requieren herramientas que ejecuten JavaScript.

---

### 2Ô∏è‚É£ IDENTIFICACI√ìN DE VALORES

#### Problema
Una vez que Selenium obtiene el HTML completo, la p√°gina contiene **muchos n√∫meros** (tel√©fonos, fechas, porcentajes, etc.). ¬øC√≥mo identificar cu√°les son los tipos de cambio?

```html
<!-- Ejemplo de HTML con muchos n√∫meros -->
<div>Ll√°manos: 01-234-5678</div>
<div>Tasa: 3.42</div>
<div>Comisi√≥n: 0.5%</div>
<div>Compra: 3.38</div>
<div>Fecha: 26/12/2025</div>
```

#### Soluci√≥n
Desarrollamos una estrategia de **extracci√≥n con regex + filtrado por rango**:

```python
import re

# 1. Extraer todos los n√∫meros con formato decimal
patron = r'[\d]+\.[\d]{2,4}'
valores = re.findall(patron, page_source)
# Resultado: ['234.5678', '3.42', '0.5', '3.38', '26.12', '2025']

# 2. Filtrar solo los que est√°n en rango v√°lido de tipo de cambio
valores_tc = [float(v) for v in valores if 3.30 <= float(v) <= 3.50]
# Resultado: [3.42, 3.38]

# 3. El menor es COMPRA, el mayor es VENTA
compra = min(valores_tc)
venta = max(valores_tc)
```

#### ¬øPor qu√© el rango 3.30 - 3.50?
- El tipo de cambio PEN/USD hist√≥ricamente fluct√∫a en este rango
- Valores fuera de este rango claramente no son tipo de cambio
- El rango puede ajustarse si el mercado cambia significativamente

#### Lecci√≥n aprendida
> Cuando el HTML no tiene estructura clara, las expresiones regulares combinadas con filtros de dominio son una soluci√≥n efectiva.

---

### 3Ô∏è‚É£ TIEMPOS DE ESPERA

#### Problema
Selenium tardaba demasiado en algunas ejecuciones (30+ segundos por p√°gina), haciendo el sistema lento e impredecible.

#### Causas identificadas
1. `time.sleep()` fijo esperaba m√°s de lo necesario
2. Carga de im√°genes y recursos innecesarios
3. Inicializaci√≥n del navegador en cada llamada

#### Soluci√≥n
Implementamos varias optimizaciones:

```python
# 1. Deshabilitar carga de im√°genes
options.add_argument('--blink-settings=imagesEnabled=false')

# 2. Deshabilitar extensiones
options.add_argument('--disable-extensions')

# 3. Modo headless (sin interfaz gr√°fica)
options.add_argument('--headless')

# 4. Esperas m√°s inteligentes (esperar elemento espec√≠fico)
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

wait = WebDriverWait(driver, 10)
# Esperar hasta que aparezca un elemento con n√∫meros
```

#### Resultado
- Tiempo promedio reducido de 30s a 10-15s por scraper
- Mayor consistencia en los tiempos de respuesta

#### Lecci√≥n aprendida
> Las optimizaciones de Selenium pueden reducir significativamente los tiempos. Deshabilitar recursos innecesarios y usar esperas inteligentes es clave.

---

### 4Ô∏è‚É£ API BCRP - FORMATO DE FECHAS

#### Problema
La API del BCRP requiere fechas en formato espec√≠fico `YYYY-MM-DD` y un rango v√°lido. Si el rango es incorrecto o incluye d√≠as sin datos (fines de semana), la API retorna errores o datos vac√≠os.

```python
# ‚ùå ESTO FALLABA
url = "https://estadisticas.bcrp.gob.pe/.../2025-12-25/2025-12-25"
# Error: No hay datos para el 25 de diciembre (feriado)
```

#### Soluci√≥n
Creamos una funci√≥n que genera un rango de fechas inteligente:

```python
from datetime import datetime, timedelta

def generar_rango_fechas():
    """
    Genera un rango de 7 d√≠as hacia atr√°s para asegurar
    que siempre haya al menos un d√≠a h√°bil con datos.
    """
    hoy = datetime.now()
    hace_7_dias = hoy - timedelta(days=7)
    
    fecha_inicio = hace_7_dias.strftime('%Y-%m-%d')
    fecha_fin = hoy.strftime('%Y-%m-%d')
    
    return fecha_inicio, fecha_fin

# Uso
fecha_inicio, fecha_fin = generar_rango_fechas()
url = f"https://estadisticas.bcrp.gob.pe/.../json/{fecha_inicio}/{fecha_fin}"
```

#### Manejo de respuesta
```python
# Tomamos el √∫ltimo per√≠odo disponible
periodos = data['periods']
ultimo_periodo = periodos[-1]  # El m√°s reciente con datos
```

#### Lecci√≥n aprendida
> Las APIs gubernamentales pueden tener particularidades. Es importante manejar casos edge como feriados y fines de semana.

---

### 5Ô∏è‚É£ COMPATIBILIDAD NICEGUI 3.4.1

#### Problema
Al desarrollar la aplicaci√≥n web con NiceGUI, encontramos que la versi√≥n 3.4.1 tiene cambios respecto a versiones anteriores que causaban errores.

#### Errores encontrados

**Error 1: `ui.header()` anidado**
```python
# ‚ùå ERROR
with ui.column():
    with ui.header():  # RuntimeError: Header no puede estar anidado
        ...
```

**Error 2: `ui.html()` requiere par√°metro**
```python
# ‚ùå ERROR
ui.html('<h1>T√≠tulo</h1>')  # TypeError: missing argument 'sanitize'
```

#### Soluciones

**Soluci√≥n 1: Usar `ui.row()` en lugar de `ui.header()`**
```python
# ‚úÖ FUNCIONA
with ui.row().classes('w-full p-4 bg-gray-900'):
    ui.label('TipoCambio.pe').classes('text-2xl font-bold')
```

**Soluci√≥n 2: Usar `ui.label()` con clases Tailwind**
```python
# ‚úÖ FUNCIONA
ui.label('T√≠tulo').classes('text-5xl font-bold text-cyan-400')
```

#### Lecci√≥n aprendida
> Las librer√≠as evolucionan y pueden introducir breaking changes. Es importante revisar changelogs y adaptar el c√≥digo.

---

### 6Ô∏è‚É£ COORDINACI√ìN DE EQUIPO

#### Problema
Coordinar el trabajo de 3 personas con diferentes horarios y responsabilidades.

#### Soluci√≥n
Implementamos buenas pr√°cticas de desarrollo colaborativo:

**1. Estructura de commits descriptivos**
```
feat: agregar scraper de Kambista con Selenium
fix: corregir extracci√≥n de valores en Rextie
docs: actualizar README con instrucciones de instalaci√≥n
```

**2. Distribuci√≥n clara de tareas**

| Integrante | Responsabilidad |
|------------|-----------------|
| Javier Uraco | Scrapers BCRP/Rextie, Integrador, App Web |
| Fiorella Fuentes | Scraper Kambista, App Web, DIFICULTADES |
| Sebasti√°n Fern√°ndez | Documentaci√≥n, README |

**3. Revisi√≥n de c√≥digo**
- Cada PR era revisado antes de merge
- Comentarios constructivos para mejorar el c√≥digo

#### Lecci√≥n aprendida
> El trabajo en equipo requiere comunicaci√≥n clara, herramientas adecuadas (GitHub) y distribuci√≥n equitativa de responsabilidades.

---

## üìä Resumen de Tecnolog√≠as por Dificultad

| Dificultad | Tecnolog√≠a inicial | Tecnolog√≠a final |
|------------|-------------------|------------------|
| P√°ginas din√°micas | BeautifulSoup | Selenium |
| Identificaci√≥n valores | Selectores CSS | Regex + filtros |
| Tiempos espera | time.sleep() fijo | WebDriverWait + optimizaciones |
| Fechas API | Fecha fija | Rango din√°mico 7 d√≠as |
| UI Web | ui.html() | ui.label() + Tailwind |
| Colaboraci√≥n | Archivos compartidos | Git + GitHub |

---

## üéØ Conclusi√≥n

Cada dificultad nos oblig√≥ a investigar, probar alternativas y aprender nuevas t√©cnicas. El proceso de debugging y soluci√≥n de problemas fue una parte fundamental del aprendizaje en este proyecto.

Las principales lecciones fueron:
1. **Investigar antes de implementar** - Entender c√≥mo funciona una p√°gina/API antes de escribir c√≥digo
2. **Manejar errores proactivamente** - Anticipar qu√© puede fallar y tener planes de contingencia
3. **Documentar soluciones** - Para referencia futura y para el equipo
4. **Iterar y mejorar** - La primera soluci√≥n raramente es la mejor

---

**Documento elaborado por el equipo TipoCambio.pe - LP2 UNALM 2025**
